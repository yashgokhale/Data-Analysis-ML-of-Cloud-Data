{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import netcdf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "import matplotlib.style\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os,sys\n",
    "os.chdir('C:/Users/yashg/Documents/Cloud_Data_Files')\n",
    "def read_files(extensions,location):\n",
    "    l=[]\n",
    "    for types in extensions:\n",
    "        l.append(glob.glob(f'./{location}/*{types}'))\n",
    "    l=[val for sublist in l for val in sublist]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=read_files(['.cdf','.nc'],'KAZRARSCL')\n",
    "m=read_files(['.cdf','.nc'],'Microbase')\n",
    "r=read_files(['.cdf','.nc'],'Raman Lidar')\n",
    "s=read_files(['.cdf','.nc'],'Surface')\n",
    "master=k+m+r+s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_files(date,master=master):\n",
    "    f=[]\n",
    "    for file in master:\n",
    "        if date in file:\n",
    "            f.append(file)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=['20110505','20110513','20110514','20110515','20110519','20110527','20110528','20110529','20110601']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cdfs(date):\n",
    "    l=[]\n",
    "    f=date_files(date)\n",
    "    for file in f:\n",
    "        l.append(Dataset(file))\n",
    "    print('Output has 4 files')\n",
    "    print('File order is\\t1.KAZRARSCL\\t2.Microbase\\t3.Raman Lidar\\t4. Surface')\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_clustering(z1,z2):\n",
    "    \"\"\"\n",
    "    z2 is the heights for the higher resolved data whereas\n",
    "    z1 is the heights for the lower resolved data\n",
    "    eg: z1-Raman Lidar\n",
    "        z2-Microbase,KAZRARSCL\n",
    "    \"\"\"\n",
    "    z_index=[]\n",
    "    for i in range(len(z1)-1):\n",
    "        arg=[]\n",
    "        for j in range(len(z2)):\n",
    "            if z2[j]>=z1[i] and z2[j]<=z1[i+1]:\n",
    "                arg.append(j)\n",
    "        z_index.append(arg)\n",
    "    return z_index\n",
    "\n",
    "def temporal_clustering(t1,t2):\n",
    "    \"\"\"\n",
    "    t2 is the heights for the higher resolved data whereas\n",
    "    t1 is the heights for the lower resolved data\n",
    "    eg: t1-Raman Lidar\n",
    "        t2-Microbase,KAZRARSCL\n",
    "    \"\"\"\n",
    "    t_index=[]\n",
    "    for i in range(len(t1)-1):\n",
    "        arg=[]\n",
    "        for j in range(len(t2)):\n",
    "            if t2[j]>=t1[i] and t2[j]<=t1[i+1]:\n",
    "                arg.append(j)\n",
    "        t_index.append(arg)\n",
    "    return t_index\n",
    "\n",
    "def spatio_temporal_clustering(z1,z2,t1,t2,pars):\n",
    "    \"\"\"\n",
    "    2 is the higher resolved data whereas\n",
    "    1 is the lower resolved data\n",
    "    eg: 1-Raman Lidar\n",
    "        2-Microbase,KAZRARSCL\n",
    "    pars: Parameter for which you have to cluster\n",
    "    \"\"\" \n",
    "    hargs=spatial_clustering(z1,z2)\n",
    "    targs=temporal_clustering(t1,t2)\n",
    "    par_array=[]\n",
    "    u=0\n",
    "    for i in targs:\n",
    "        for j in hargs:\n",
    "            e1=[]\n",
    "            for m in i:\n",
    "                for n in j:\n",
    "                    e1.append(pars[m,n])\n",
    "            par_array.append(e1)\n",
    "    return par_array\n",
    "\n",
    "def filtering(z1,z2,t1,t2,param):\n",
    "    miss=param.missing_value\n",
    "    pars=np.ma.filled(param[:])\n",
    "    par=spatio_temporal_clustering(z1,z2,t1,t2,pars)\n",
    "    avg=[]\n",
    "    stdev=[]\n",
    "    for i in range(len(par)):\n",
    "        par[i]=np.array(par[i])\n",
    "        par[i]=par[i][par[i]!=miss]\n",
    "        avg.append(par[i].mean())\n",
    "        stdev.append(par[i].std())\n",
    "    return avg,stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of extinction\n",
    "def extinction(file,tr,threshold=29):\n",
    "    base_h=np.zeros(len(tr))\n",
    "    extin_h=np.zeros(len(tr))\n",
    "    for i in range(len(file)):\n",
    "        em=file[i]\n",
    "        for k,j in enumerate(em):\n",
    "            if j>threshold:\n",
    "                base_h[i]=k\n",
    "                extin_h[i]=j\n",
    "                break\n",
    "    return base_h,extin_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_base(z1,z2,t1,t2,param,ext,low,up,threshold=29):\n",
    "    l=[]\n",
    "    ls=[]\n",
    "    par_avg,par_std=filtering(z1,z2,t1,t2,param)\n",
    "    rplot=np.array(par_avg).reshape(len(t1)-1,len(z1)-1)\n",
    "    rstd=np.array(par_std).reshape(len(t1)-1,len(z1)-1)\n",
    "    arg=extinction(ext,t1,threshold=threshold)[0][1:]\n",
    "    for i in range(len(rplot)):\n",
    "        l.append(rplot[i,int(arg[i])])\n",
    "        ls.append(rstd[i,int(arg[i])])\n",
    "    xx=np.argwhere((t1>=low) & (t1<=up))\n",
    "    return np.array(l)[xx],np.array(ls)[xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_output(d,down,up):\n",
    "    k1,m1,r1,s1=generate_cdfs(d)\n",
    "    tm=np.ma.filled(m1['time'][:])\n",
    "    hm=np.ma.filled(m1['height'][:])\n",
    "    tr=np.ma.filled(r1['time'][:])\n",
    "    hr=np.ma.filled(r1['height'][:])*1000\n",
    "    lwc=m1['liquid_water_content']\n",
    "    temp=np.ma.filled(r1['temperature'][:])\n",
    "    ext=np.ma.filled(r1['ext'][:])\n",
    "    mdv=k1['mean_doppler_velocity']\n",
    "    arge,ex=extinction(ext,tr)\n",
    "    xx=np.argwhere((tr>=down) & (tr<=up))\n",
    "    ex=np.array(ex)[xx]\n",
    "    arge=np.array(arge)[xx]\n",
    "    ex = [item for sublist in ex for item in sublist]\n",
    "    dd=[d]*len(xx)\n",
    "    tim=tr[xx]\n",
    "    tim = [item for sublist in tim for item in sublist]\n",
    "    t=[]\n",
    "    for i in range(len(arge)):\n",
    "        t.append(temp[int(xx[i]),int(arge[i])])\n",
    "    l,dl=timeseries_base(hr,hm,tr,tm,lwc,ext,down,up)\n",
    "    v,dv=timeseries_base(hr,hm,tr,tm,mdv,ext,down,up)\n",
    "    l=np.squeeze(l)\n",
    "    dl=np.squeeze(dl)\n",
    "    v=np.squeeze(v)\n",
    "    dv=np.squeeze(dv)\n",
    "    df={'Date':dd,\n",
    "        'Time(s)':tim,\n",
    "        'LWC':l,\n",
    "        'LWC_sd':dl,\n",
    "        'Mean_Doppler_Velocity':v,\n",
    "        'Mean_Doppler_Velocity_sd':dv,\n",
    "        'Extinction':ex,\n",
    "        'Temperature':t}\n",
    "    data=pd.DataFrame(df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output has 4 files\n",
      "File order is\t1.KAZRARSCL\t2.Microbase\t3.Raman Lidar\t4. Surface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: Mean of empty slice.\n",
      "C:\\Users\\yashg\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\yashg\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\yashg\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\Users\\yashg\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output has 4 files\n",
      "File order is\t1.KAZRARSCL\t2.Microbase\t3.Raman Lidar\t4. Surface\n",
      "Output has 4 files\n",
      "File order is\t1.KAZRARSCL\t2.Microbase\t3.Raman Lidar\t4. Surface\n",
      "Output has 4 files\n",
      "File order is\t1.KAZRARSCL\t2.Microbase\t3.Raman Lidar\t4. Surface\n",
      "Output has 4 files\n",
      "File order is\t1.KAZRARSCL\t2.Microbase\t3.Raman Lidar\t4. Surface\n"
     ]
    }
   ],
   "source": [
    "d13=data_output('20110513',30000,85000)\n",
    "d14=data_output('20110514',10000,50000)\n",
    "d191=data_output('20110519',0,15000)\n",
    "d192=data_output('20110519',35000,40000)\n",
    "d29=data_output('20110529',500,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[d13,d14,d191,d192,d29]\n",
    "data_combined=pd.concat(frames,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined.to_csv('C:/Users/yashg/Documents/Cloud_Data_Files/filtered_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
